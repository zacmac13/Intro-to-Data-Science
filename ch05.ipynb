{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5  Getting Started with pandas\n",
    "\n",
    "Throughout the remaining chapters of the book, pandas will be a central focus. It offers data structures and tools for manipulating data in Python, streamlining the processes of data cleaning and analysis. pandas is commonly utilized alongside numerical computing tools like NumPy and SciPy, analytical libraries such as statsmodels and scikit-learn, and data visualization libraries like matplotlib. While pandas borrows coding styles from NumPy, its primary distinction lies in its specialization for working with tabular or diverse data, unlike NumPy, which excels with homogeneously typed numerical array data.\n",
    "\n",
    "Since its transition to an open-source project in 2010, pandas has evolved into a substantial library applicable to a wide range of real-world scenarios. With a developer community exceeding 2,500 contributors, the project has grown significantly, benefitting from the collective expertise of individuals who have actively used it to address their day-to-day data challenges. The thriving pandas developer and user communities have played a pivotal role in the success of the library.\n",
    "\n",
    "For the remainder of the book, We'll stick to the following import conventions for NumPy and pandas:\n",
    "\n",
    "```python\n",
    "In [1]: import numpy as np\n",
    "\n",
    "In [2]: import pandas as pd\n",
    "```\n",
    "\n",
    "So, whenever you encounter `pd.` in the code, it's essentially shorthand for pandas. To simplify things further, you might find it convenient to bring Series and DataFrame directly into the local namespace, considering their frequent usage:\n",
    "\n",
    "```python\n",
    "In [3]: from pandas import Series, DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Introduction to pandas Data Structures\n",
    "\n",
    "Getting started with pandas involves becoming acquainted with its two primary data structures: Series and DataFrame. While they may not be a one-size-fits-all solution, they serve as a robust foundation for a diverse array of data tasks.\n",
    "\n",
    "### Series\n",
    "A Series is akin to a one-dimensional array, containing a sequence of values (similar to NumPy types) and an associated array of data labels called its index. The simplest Series is created with just an array of data:\n",
    "\n",
    "```python\n",
    "In [14]: obj = pd.Series([4, 7, -5, 3])\n",
    "\n",
    "In [15]: obj\n",
    "Out[15]: \n",
    "0    4\n",
    "1    7\n",
    "2   -5\n",
    "3    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "The index is automatically generated as integers when not specified. You can access the array representation and index using `obj.array` and `obj.index` respectively.\n",
    "\n",
    "```python\n",
    "In [16]: obj.array\n",
    "Out[16]: \n",
    "<PandasArray>\n",
    "[4, 7, -5, 3]\n",
    "Length: 4, dtype: int64\n",
    "\n",
    "In [17]: obj.index\n",
    "Out[17]: RangeIndex(start=0, stop=4, step=1)\n",
    "```\n",
    "\n",
    "You can create a Series with a labeled index:\n",
    "\n",
    "```python\n",
    "In [18]: obj2 = pd.Series([4, 7, -5, 3], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "```\n",
    "\n",
    "Accessing values using labels is possible, and operations maintain the link between index and values:\n",
    "\n",
    "```python\n",
    "In [21]: obj2[\"a\"]\n",
    "Out[21]: -5\n",
    "\n",
    "In [24]: obj2[obj2 > 0]\n",
    "Out[24]: \n",
    "d    6\n",
    "b    7\n",
    "c    3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "A Series can be viewed as a fixed-length, ordered dictionary. You can create one from a dictionary or convert it back using `to_dict()`.\n",
    "\n",
    "```python\n",
    "In [32]: obj3 = pd.Series({\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000})\n",
    "```\n",
    "\n",
    "Handling missing data, labeled arithmetic operations, and assigning names to the Series and its index are essential aspects explored in this introduction to Series. The alignment of data based on index labels during arithmetic operations is a feature reminiscent of a join operation in databases.\n",
    "\n",
    "```python\n",
    "In [42]: obj3 + obj4\n",
    "Out[42]: \n",
    "California         NaN\n",
    "Ohio           70000.0\n",
    "Oregon         32000.0\n",
    "Texas         142000.0\n",
    "Utah               NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Lastly, both the Series object and its index can have a name attribute, integrating with other pandas functionalities. The index of a Series can be modified in place by assignment.\n",
    "\n",
    "Both the Series object and its index come equipped with a name attribute, seamlessly integrating with various aspects of pandas functionality:\n",
    "\n",
    "```python\n",
    "In [43]: obj4.name = \"population\"\n",
    "\n",
    "In [44]: obj4.index.name = \"state\"\n",
    "\n",
    "In [45]: obj4\n",
    "Out[45]: \n",
    "state\n",
    "California        NaN\n",
    "Ohio          35000.0\n",
    "Oregon        16000.0\n",
    "Texas         71000.0\n",
    "Name: population, dtype: float64\n",
    "```\n",
    "\n",
    "Assigning a name to the Series object as a whole (`obj4.name`) and naming its index (`obj4.index.name`) enhances clarity, especially when dealing with multiple Series in a broader analysis or when combining data from different sources.\n",
    "\n",
    "Additionally, you can modify a Series's index directly through assignment:\n",
    "\n",
    "```python\n",
    "In [46]: obj\n",
    "Out[46]: \n",
    "0    4\n",
    "1    7\n",
    "2   -5\n",
    "3    3\n",
    "dtype: int64\n",
    "\n",
    "In [47]: obj.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]\n",
    "\n",
    "In [48]: obj\n",
    "Out[48]: \n",
    "Bob      4\n",
    "Steve    7\n",
    "Jeff    -5\n",
    "Ryan     3\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "This flexibility allows you to personalize the index to better reflect the context of your data, making it more meaningful and interpretable in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "PREVIOUS_MAX_ROWS = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_colwidth = 80\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    7\n",
       "2   -5\n",
       "3    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.Series([4, 7, -5, 3])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NumpyExtensionArray>\n",
       "[4, 7, -5, 3]\n",
       "Length: 4, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d', 'b', 'a', 'c'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2 = pd.Series([4, 7, -5, 3], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "obj2\n",
    "obj2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2[\"a\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    6\n",
       "b    7\n",
       "a   -5\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2[\"d\"] = 6\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    3\n",
       "a   -5\n",
       "d    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2[[\"c\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    6\n",
       "b    7\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2[obj2 > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d    12\n",
       "b    14\n",
       "a   -10\n",
       "c     6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2 * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d     403.428793\n",
       "b    1096.633158\n",
       "a       0.006738\n",
       "c      20.085537\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"b\" in obj2\n",
    "\"e\" in obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio      35000\n",
       "Texas     71000\n",
       "Oregon    16000\n",
       "Utah       5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj3.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California        NaN\n",
       "Ohio          35000.0\n",
       "Oregon        16000.0\n",
       "Texas         71000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n",
    "obj4 = pd.Series(sdata, index=states)\n",
    "obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    False\n",
       "Ohio           True\n",
       "Oregon         True\n",
       "Texas          True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(obj4)\n",
    "pd.notna(obj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California     True\n",
       "Ohio          False\n",
       "Oregon        False\n",
       "Texas         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj4.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California         NaN\n",
       "Ohio           70000.0\n",
       "Oregon         32000.0\n",
       "Texas         142000.0\n",
       "Utah               NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj3\n",
    "obj4\n",
    "obj3 + obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "California        NaN\n",
       "Ohio          35000.0\n",
       "Oregon        16000.0\n",
       "Texas         71000.0\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj4.name = \"population\"\n",
    "obj4.index.name = \"state\"\n",
    "obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bob      4\n",
       "Steve    7\n",
       "Jeff    -5\n",
       "Ryan     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj\n",
    "obj.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "1. **Series with Labels:**\n",
    "   - Create a new Series named `obj2` with the values [4, 7, -5, 3] with labels [\"d\", \"b\", \"a\", \"c\"]. Display the Series and its index.\n",
    "\n",
    "2. **Accessing and Modifying Elements:**\n",
    "   - Retrieve the value associated with the label \"a\" from `obj2`.\n",
    "   - Change the value associated with the label \"d\" in `obj2` to 6.\n",
    "   - Display the subset of `obj2` containing values with labels [\"c\", \"a\", \"d\"].\n",
    "\n",
    "3. **NumPy-like Operations on Series:**\n",
    "   - Display the elements of `obj2` that are greater than 0.\n",
    "   - Multiply all elements of `obj2` by 2.\n",
    "   - Calculate the exponential of each element in `obj2` using NumPy's `exp` function.\n",
    "\n",
    "4. **Series as a Dictionary:**\n",
    "   - Check if the label \"b\" is present in `obj2`.\n",
    "   - Check if the label \"e\" is present in `obj2`.\n",
    "   - Create a Series named `obj3` from the dictionary `sdata` provided in the material. Display the resulting Series.\n",
    "\n",
    "5. **Handling Missing Data:**\n",
    "   - Display a boolean Series indicating whether each element in `obj4` is missing (NaN).\n",
    "   - Display a boolean Series indicating whether each element in `obj4` is not missing.\n",
    "\n",
    "7. **Series Attributes:**\n",
    "   - Give the Series `obj4` the name \"population\" and name its index \"state\". Display the updated Series.\n",
    "\n",
    "7. **Changing Index Labels:**\n",
    "   - Change the index of the `obj` Series to [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]. Display the updated Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "A DataFrame is a structured representation of tabular data, resembling a two-dimensional table, containing columns with different data types such as numeric, string, or Boolean values. It consists of both row and column indices, akin to a dictionary where each column is a Series sharing the same index.\n",
    "\n",
    "The DataFrame can also be utilized for organizing data beyond two dimensions by employing hierarchical indexing, which we'll delve into in Chapter 8: Data Wrangling: Join, Combine, and Reshape, and is foundational for more advanced data manipulation functionalities in pandas.\n",
    "\n",
    "Constructing a DataFrame can be achieved through various methods, but one common approach is using a dictionary comprising lists or NumPy arrays of equal length:\n",
    "\n",
    "```python\n",
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "The resulting DataFrame is automatically assigned an index, akin to Series, and the columns are arranged based on the order of keys in the data dictionary, preserving their insertion order:\n",
    "\n",
    "```\n",
    "    state  year  pop\n",
    "0    Ohio  2000  1.5\n",
    "1    Ohio  2001  1.7\n",
    "2    Ohio  2002  3.6\n",
    "3  Nevada  2001  2.4\n",
    "4  Nevada  2002  2.9\n",
    "5  Nevada  2003  3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2002</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2003</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  pop\n",
       "0    Ohio  2000  1.5\n",
       "1    Ohio  2001  1.7\n",
       "2    Ohio  2002  3.6\n",
       "3  Nevada  2001  2.4\n",
       "4  Nevada  2002  2.9\n",
       "5  Nevada  2003  3.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n",
    "        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data)\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head` method in pandas DataFrame retrieves the first five rows of the DataFrame. This is useful when dealing with large datasets as it provides a concise preview of the data. For example, given a DataFrame named `frame`, calling `frame.head()` will return the first five rows as shown below:\n",
    "\n",
    "```\n",
    "   state  year  pop\n",
    "0   Ohio  2000  1.5\n",
    "1   Ohio  2001  1.7\n",
    "2   Ohio  2002  3.6\n",
    "3 Nevada  2001  2.4\n",
    "4 Nevada  2002  2.9\n",
    "```\n",
    "\n",
    "Conversely, the `tail` method retrieves the last five rows of the DataFrame. This can be helpful for checking the end of the dataset. Similarly, given the same DataFrame `frame`, calling `frame.tail()` will return the last five rows:\n",
    "\n",
    "```\n",
    "   state  year  pop\n",
    "1   Ohio  2001  1.7\n",
    "2   Ohio  2002  3.6\n",
    "3 Nevada  2001  2.4\n",
    "4 Nevada  2002  2.9\n",
    "5 Nevada  2003  3.2\n",
    "```\n",
    "\n",
    "When creating a DataFrame, you can specify the order of columns using the `columns` parameter. This allows you to arrange the columns as desired. For example, if `data` is a dictionary containing the data, you can create a DataFrame with specific column order like this:\n",
    "\n",
    "```\n",
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])\n",
    "```\n",
    "\n",
    "This will result in a DataFrame where the columns are arranged as specified.\n",
    "\n",
    "If you provide a column name that is not present in the dictionary used to create the DataFrame, it will appear with missing values in the resulting DataFrame. For instance, if you create a DataFrame `frame2` with an additional column named \"debt\", but it's not present in the original data, it will show up with NaN values:\n",
    "\n",
    "```\n",
    "   year   state  pop debt\n",
    "0  2000    Ohio  1.5  NaN\n",
    "1  2001    Ohio  1.7  NaN\n",
    "2  2002    Ohio  3.6  NaN\n",
    "3  2001  Nevada  2.4  NaN\n",
    "4  2002  Nevada  2.9  NaN\n",
    "5  2003  Nevada  3.2  NaN\n",
    "```\n",
    "\n",
    "Columns in a DataFrame can be accessed as Series using either dictionary-like notation (`frame2[\"state\"]`) or dot attribute notation (`frame2.state`). However, the latter method (`frame2.column`) only works when the column name is a valid Python variable name and does not conflict with any DataFrame method names. It's worth noting that both methods return Series objects with the same index as the DataFrame, and their name attributes are appropriately set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2002</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  pop\n",
       "0    Ohio  2000  1.5\n",
       "1    Ohio  2001  1.7\n",
       "2    Ohio  2002  3.6\n",
       "3  Nevada  2001  2.4\n",
       "4  Nevada  2002  2.9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2002</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2003</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  pop\n",
       "1    Ohio  2001  1.7\n",
       "2    Ohio  2002  3.6\n",
       "3  Nevada  2001  2.4\n",
       "4  Nevada  2002  2.9\n",
       "5  Nevada  2003  3.2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop\n",
       "0  2000    Ohio  1.5\n",
       "1  2001    Ohio  1.7\n",
       "2  2002    Ohio  3.6\n",
       "3  2001  Nevada  2.4\n",
       "4  2002  Nevada  2.9\n",
       "5  2003  Nevada  3.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop debt\n",
       "0  2000    Ohio  1.5  NaN\n",
       "1  2001    Ohio  1.7  NaN\n",
       "2  2002    Ohio  3.6  NaN\n",
       "3  2001  Nevada  2.4  NaN\n",
       "4  2002  Nevada  2.9  NaN\n",
       "5  2003  Nevada  3.2  NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])\n",
    "frame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'state', 'pop', 'debt'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Ohio\n",
       "1      Ohio\n",
       "2      Ohio\n",
       "3    Nevada\n",
       "4    Nevada\n",
       "5    Nevada\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2[\"state\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mframe2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "frame2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows can be retrieved either by their position or by their label using the special `iloc` and `loc` attributes, respectively. These methods allow for more flexible and precise row selection. \n",
    "\n",
    "For example, using the `loc` attribute on a DataFrame like `frame2`, you can retrieve a row by its label. In the provided code snippet, `frame2.loc[1]` returns the row labeled '1':\n",
    "\n",
    "```\n",
    "year     2001\n",
    "state    Ohio\n",
    "pop       1.7\n",
    "debt      NaN\n",
    "Name: 1, dtype: object\n",
    "```\n",
    "\n",
    "Similarly, the `iloc` attribute allows for row retrieval by position. In the given code, `frame2.iloc[2]` retrieves the row at position 2 (zero-indexed):\n",
    "\n",
    "```\n",
    "year     2002\n",
    "state    Ohio\n",
    "pop       3.6\n",
    "debt      NaN\n",
    "Name: 2, dtype: object\n",
    "```\n",
    "\n",
    "Both `loc` and `iloc` provide powerful methods for accessing specific rows in a DataFrame, enabling tasks such as filtering and manipulation based on either labels or positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year     2001\n",
       "state    Ohio\n",
       "pop       1.7\n",
       "debt      NaN\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.loc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year     2002\n",
       "state    Ohio\n",
       "pop       3.6\n",
       "debt      NaN\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in a pandas DataFrame can be easily modified by assignment. For instance, you can assign a scalar value or an array of values to a column. Here are a few examples:\n",
    "\n",
    "```python\n",
    "# Assigning a scalar value to the 'debt' column\n",
    "frame2[\"debt\"] = 16.5\n",
    "\n",
    "# Assigning an array of values to the 'debt' column\n",
    "frame2[\"debt\"] = np.arange(6.)\n",
    "\n",
    "# Assigning a Series to the 'debt' column\n",
    "val = pd.Series([-1.2, -1.5, -1.7], index=[2, 4, 5])\n",
    "frame2[\"debt\"] = val\n",
    "```\n",
    "\n",
    "In each case, the DataFrame `frame2` is updated accordingly. When assigning lists, arrays, or Series to a column, the length of the value must match the length of the DataFrame. If a Series is assigned, its labels will be aligned with the DataFrame's index, and missing values will be inserted for any index values not present in the DataFrame.\n",
    "\n",
    "Additionally, you can create new columns by assigning values to a column that doesn't exist. For instance, in the code snippet below, a new column named 'eastern' is created based on a condition:\n",
    "\n",
    "```python\n",
    "frame2[\"eastern\"] = frame2[\"state\"] == \"Ohio\"\n",
    "```\n",
    "\n",
    "However, it's important to note that new columns cannot be created using the dot attribute notation (`frame2.eastern`). \n",
    "\n",
    "If you need to delete columns, you can use the `del` keyword, similar to deleting keys in a dictionary. For example, to remove the 'eastern' column:\n",
    "\n",
    "```python\n",
    "del frame2[\"eastern\"]\n",
    "```\n",
    "\n",
    "After deletion, you can verify the columns of the DataFrame using the `columns` attribute (`frame2.columns`). \n",
    "\n",
    "It's crucial to be cautious when modifying columns, especially since modifications to a Series obtained from a DataFrame view will reflect in the DataFrame itself. If you need to modify a Series without affecting the original DataFrame, you can explicitly copy the Series using the `copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>3.2</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop  debt\n",
       "0  2000    Ohio  1.5  16.5\n",
       "1  2001    Ohio  1.7  16.5\n",
       "2  2002    Ohio  3.6  16.5\n",
       "3  2001  Nevada  2.4  16.5\n",
       "4  2002  Nevada  2.9  16.5\n",
       "5  2003  Nevada  3.2  16.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2[\"debt\"] = 16.5\n",
    "frame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop  debt\n",
       "0  2000    Ohio  1.5   0.0\n",
       "1  2001    Ohio  1.7   1.0\n",
       "2  2002    Ohio  3.6   2.0\n",
       "3  2001  Nevada  2.4   3.0\n",
       "4  2002  Nevada  2.9   4.0\n",
       "5  2003  Nevada  3.2   5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2[\"debt\"] = np.arange(6.)\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop  debt\n",
       "0  2000    Ohio  1.5   NaN\n",
       "1  2001    Ohio  1.7   NaN\n",
       "2  2002    Ohio  3.6   NaN\n",
       "3  2001  Nevada  2.4   NaN\n",
       "4  2002  Nevada  2.9   NaN\n",
       "5  2003  Nevada  3.2   NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.Series([-1.2, -1.5, -1.7], index=[\"two\", \"four\", \"five\"])\n",
    "frame2[\"debt\"] = val\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "      <th>eastern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop  debt  eastern\n",
       "0  2000    Ohio  1.5   NaN     True\n",
       "1  2001    Ohio  1.7   NaN     True\n",
       "2  2002    Ohio  3.6   NaN     True\n",
       "3  2001  Nevada  2.4   NaN    False\n",
       "4  2002  Nevada  2.9   NaN    False\n",
       "5  2003  Nevada  3.2   NaN    False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2[\"eastern\"] = frame2[\"state\"] == \"Ohio\"\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'state', 'pop', 'debt'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del frame2[\"eastern\"]\n",
    "frame2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common data structure is a nested dictionary of dictionaries. Here, the outer dictionary keys typically represent the column names, while the inner dictionary keys serve as row indices, with their corresponding values being the data points.\n",
    "\n",
    "For example, consider the following nested dictionary named `populations`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = {\"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n",
    "               \"Nevada\": {2001: 2.4, 2002: 2.9}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass this nested dictionary to a pandas DataFrame, pandas will interpret the outer dictionary keys as the columns and the inner keys as the row indices. The resulting DataFrame, `frame3`, will look like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Nevada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>1.7</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ohio  Nevada\n",
       "2000   1.5     NaN\n",
       "2001   1.7     2.4\n",
       "2002   3.6     2.9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame3 = pd.DataFrame(populations)\n",
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the columns represent the states (\"Ohio\" and \"Nevada\"), and the rows correspond to the years (2000, 2001, and 2002). The values in the DataFrame are filled according to the data provided in the nested dictionary. For instance, in the year 2000, the population of Ohio is 1.5, while no population data is available for Nevada in that year (hence, it's represented as NaN, meaning \"Not a Number\").\n",
    "\n",
    "You can transpose a DataFrame, swapping its rows and columns, using syntax similar to that of a NumPy array. For instance, calling `.T` on the DataFrame `frame3` will transpose it:\n",
    "\n",
    "```python\n",
    "frame3.T\n",
    "```\n",
    "\n",
    "This operation results in the following transposed DataFrame:\n",
    "\n",
    "```\n",
    "        2000  2001  2002\n",
    "Ohio     1.5   1.7   3.6\n",
    "Nevada   NaN   2.4   2.9\n",
    "```\n",
    "\n",
    "It's worth noting a caveat: transposing a DataFrame discards column data types if the columns do not all have the same data type. Therefore, transposing and then transposing back may result in the loss of the previous type information, making the columns become arrays of pure Python objects.\n",
    "\n",
    "When creating a DataFrame from a nested dictionary with an explicit index, the keys in the inner dictionaries are combined to form the index in the result. For example:\n",
    "\n",
    "```python\n",
    "pd.DataFrame(populations, index=[2001, 2002, 2003])\n",
    "```\n",
    "\n",
    "This will produce a DataFrame with the specified index:\n",
    "\n",
    "```\n",
    "      Ohio  Nevada\n",
    "2001   1.7     2.4\n",
    "2002   3.6     2.9\n",
    "2003   NaN     NaN\n",
    "```\n",
    "\n",
    "Dictionaries of Series are handled similarly. For instance, if you have a dictionary `pdata` where the values are Series, you can create a DataFrame from it:\n",
    "\n",
    "```python\n",
    "pdata = {\"Ohio\": frame3[\"Ohio\"][:-1],\n",
    "         \"Nevada\": frame3[\"Nevada\"][:2]}\n",
    "pd.DataFrame(pdata)\n",
    "```\n",
    "\n",
    "This results in the following DataFrame:\n",
    "\n",
    "```\n",
    "      Ohio  Nevada\n",
    "2000   1.5     NaN\n",
    "2001   1.7     2.4\n",
    "```\n",
    "\n",
    "For a comprehensive list of data inputs that you can pass to the DataFrame constructor, refer to Table 5.1 in the documentation. This table outlines various types of data inputs and how they are interpreted when creating a DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "| Type                                    | Notes                                                                                                           |\n",
    "|-----------------------------------------|-----------------------------------------------------------------------------------------------------------------|\n",
    "| 2D ndarray                              | A matrix of data, passing optional row and column labels                                                       |\n",
    "| Dictionary of arrays, lists, or tuples | Each sequence becomes a column in the DataFrame; all sequences must be the same length                         |\n",
    "| NumPy structured/record array           | Treated as the dictionary of arrays case                                                                     |\n",
    "| Dictionary of Series                   | Each value becomes a column; indexes from each Series are unioned together to form the results row index if no explicit index is passed |\n",
    "| Dictionary of dictionaries             | Each inner dictionary becomes a column; keys are unioned to form the row index as in the dictionary of Series case |\n",
    "| List of dictionaries or Series         | Each item becomes a row in the DataFrame; unions of dictionary keys or Series indexes become the DataFrames column labels |\n",
    "| List of lists or tuples                | Treated as the 2D ndarray case                                                                               |\n",
    "| Another DataFrame                      | The DataFrames indexes are used unless different ones are passed                                              |\n",
    "| NumPy MaskedArray                      | Like the 2D ndarray case except masked values are missing in the DataFrame result                            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(populations, index=[2001, 2002, 2003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = {\"Ohio\": frame3[\"Ohio\"][:-1],\n",
    "         \"Nevada\": frame3[\"Nevada\"][:2]}\n",
    "pd.DataFrame(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.index.name = \"year\"\n",
    "frame3.columns.name = \"state\"\n",
    "frame3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Series objects, DataFrames do not have a `name` attribute. However, DataFrames provide a method called `to_numpy()` that allows you to retrieve the data stored in the DataFrame as a two-dimensional NumPy ndarray.\n",
    "\n",
    "For example, calling `frame3.to_numpy()` on a DataFrame named `frame3` will return a two-dimensional ndarray containing the DataFrame's data. Here's an illustration:\n",
    "\n",
    "```python\n",
    "frame3.to_numpy()\n",
    "```\n",
    "\n",
    "The output will resemble the following ndarray:\n",
    "\n",
    "```\n",
    "array([[1.5, nan],\n",
    "       [1.7, 2.4],\n",
    "       [3.6, 2.9]])\n",
    "```\n",
    "\n",
    "It's important to note that if the DataFrame's columns contain data of different types, the data type of the resulting ndarray will be chosen to accommodate all of the columns. This means that if the columns have mixed data types, the resulting ndarray will have the `dtype` set to `object`, which essentially treats all elements as Python objects. \n",
    "\n",
    "For instance, calling `frame2.to_numpy()` on a DataFrame named `frame2` with mixed data types will produce an ndarray with `dtype=object`:\n",
    "\n",
    "```python\n",
    "frame2.to_numpy()\n",
    "```\n",
    "\n",
    "The output will be similar to the following:\n",
    "\n",
    "```\n",
    "array([[2000, 'Ohio', 1.5, nan],\n",
    "       [2001, 'Ohio', 1.7, nan],\n",
    "       [2002, 'Ohio', 3.6, -1.2],\n",
    "       [2001, 'Nevada', 2.4, nan],\n",
    "       [2002, 'Nevada', 2.9, -1.5],\n",
    "       [2003, 'Nevada', 3.2, -1.7]], dtype=object)\n",
    "```\n",
    "\n",
    "In this example, the elements in the ndarray are treated as Python objects due to the presence of mixed data types in the DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Object\n",
    "\n",
    "Pandas' Index objects serve as containers for holding axis labels, including column names in DataFrames, along with other metadata like the axis name or names. When you construct a Series or DataFrame, any array or sequence of labels you use is internally converted to an Index object.\n",
    "\n",
    "For instance, consider creating a Series `obj` with labels \"a\", \"b\", and \"c\":\n",
    "\n",
    "```python\n",
    "obj = pd.Series(np.arange(3), index=[\"a\", \"b\", \"c\"])\n",
    "```\n",
    "\n",
    "The `index` attribute of this Series holds an Index object:\n",
    "\n",
    "```python\n",
    "index = obj.index\n",
    "```\n",
    "\n",
    "The `index` object would look like this:\n",
    "\n",
    "```\n",
    "Index(['a', 'b', 'c'], dtype='object')\n",
    "```\n",
    "\n",
    "It's important to note that Index objects are immutable, meaning they cannot be modified by the user. This immutability ensures the safety of sharing Index objects among different data structures.\n",
    "\n",
    "```python\n",
    "index[1] = \"d\"  # This will raise a TypeError\n",
    "```\n",
    "\n",
    "Despite immutability, Index objects offer capabilities similar to a fixed-size set. For example, you can check for the presence of a label within an Index:\n",
    "\n",
    "```python\n",
    "frame3.columns  # This returns Index(['Ohio', 'Nevada'], dtype='object', name='state')\n",
    "\"Ohio\" in frame3.columns  # This returns True\n",
    "```\n",
    "\n",
    "However, unlike Python sets, Index objects can contain duplicate labels. When selecting with duplicate labels, all occurrences of that label will be selected.\n",
    "\n",
    "Index objects provide a variety of methods and properties for set logic operations. Here are some useful ones:\n",
    "\n",
    "- `append()`: Concatenate with additional Index objects, producing a new Index\n",
    "- `difference()`: Compute set difference as an Index\n",
    "- `intersection()`: Compute set intersection\n",
    "- `union()`: Compute set union\n",
    "- `isin()`: Compute a Boolean array indicating whether each value is contained in the passed collection\n",
    "- `delete()`: Compute a new Index with an element at Index i deleted\n",
    "- `drop()`: Compute a new Index by deleting passed values\n",
    "- `insert()`: Compute a new Index by inserting an element at Index i\n",
    "- `is_monotonic()`: Returns True if each element is greater than or equal to the previous element\n",
    "- `is_unique()`: Returns True if the Index has no duplicate values\n",
    "- `unique()`: Compute the array of unique values in the Index\n",
    "\n",
    "These methods and properties offer valuable tools for handling and analyzing data contained within Index objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(3), index=[\"a\", \"b\", \"c\"])\n",
    "index = obj.index\n",
    "index\n",
    "index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Index(np.arange(3))\n",
    "labels\n",
    "obj2 = pd.Series([1.5, -2.5, 0], index=labels)\n",
    "obj2\n",
    "obj2.index is labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3\n",
    "frame3.columns\n",
    "\"Ohio\" in frame3.columns\n",
    "2003 in frame3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Index([\"foo\", \"foo\", \"bar\", \"bar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Essential Functionality\n",
    "\n",
    "This section provides a comprehensive overview of reindexing, a fundamental operation for aligning data in pandas Series and DataFrames. While the subsequent chapters will delve into more advanced data analysis and manipulation techniques, understanding reindexing lays a crucial foundation.\n",
    "\n",
    "**Reindexing:**\n",
    "\n",
    "Reindexing, a vital method in pandas, involves creating a new object with values rearranged to align with a new index. Let's illustrate this with examples:\n",
    "\n",
    "Consider a Series `obj`:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "```\n",
    "\n",
    "Calling `reindex` on this Series rearranges the data based on the new index, introducing missing values if necessary:\n",
    "\n",
    "```python\n",
    "obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "```\n",
    "\n",
    "For ordered data like time series, you might need to interpolate or fill values when reindexing. The `method` option allows this, with methods like `ffill` for forward-filling:\n",
    "\n",
    "```python\n",
    "obj3 = pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0, 2, 4])\n",
    "obj3.reindex(np.arange(6), method=\"ffill\")\n",
    "```\n",
    "\n",
    "In DataFrames, reindexing can alter row index, column names, or both. When given a sequence, it reindexes the rows:\n",
    "\n",
    "```python\n",
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)),\n",
    "                     index=[\"a\", \"c\", \"d\"],\n",
    "                     columns=[\"Ohio\", \"Texas\", \"California\"])\n",
    "frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "```\n",
    "\n",
    "Columns can be reindexed using the `columns` keyword:\n",
    "\n",
    "```python\n",
    "states = [\"Texas\", \"Utah\", \"California\"]\n",
    "frame.reindex(columns=states)\n",
    "```\n",
    "\n",
    "To reindex a particular axis, you can pass the new labels as a positional argument and specify the axis using the `axis` keyword:\n",
    "\n",
    "```python\n",
    "frame.reindex(states, axis=\"columns\")\n",
    "```\n",
    "\n",
    "**Table 5.3: reindex function arguments:**\n",
    "\n",
    "This table summarizes the arguments to the `reindex` function, providing a detailed explanation for each:\n",
    "\n",
    "- `labels`: New sequence to use as an index. Can be an Index instance or any other sequence-like Python data structure.\n",
    "- `index`: Use the passed sequence as the new index labels.\n",
    "- `columns`: Use the passed sequence as the new column labels.\n",
    "- `axis`: Specifies the axis to reindex, whether \"index\" (rows) or \"columns\".\n",
    "- `method`: Interpolation (fill) method; \"ffill\" fills forward, while \"bfill\" fills backward.\n",
    "- `fill_value`: Substitute value to use when introducing missing data by reindexing.\n",
    "- `limit`, `tolerance`, `level`, `copy`: Additional parameters for specifying behavior during reindexing.\n",
    "\n",
    "Lastly, while reindexing can be done using the `reindex` method, some users prefer using the `loc` operator, especially when all new index labels already exist in the DataFrame:\n",
    "\n",
    "```python\n",
    "frame.loc[[\"a\", \"d\", \"c\"], [\"California\", \"Texas\"]]\n",
    "```\n",
    "\n",
    "This snippet demonstrates reindexing using `loc`, which inserts missing data for new labels only if they already exist in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=[\"d\", \"b\", \"a\", \"c\"])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3 = pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0, 2, 4])\n",
    "obj3\n",
    "obj3.reindex(np.arange(6), method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(9).reshape((3, 3)),\n",
    "                     index=[\"a\", \"c\", \"d\"],\n",
    "                     columns=[\"Ohio\", \"Texas\", \"California\"])\n",
    "frame\n",
    "frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"Texas\", \"Utah\", \"California\"]\n",
    "frame.reindex(columns=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.reindex(states, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.loc[[\"a\", \"d\", \"c\"], [\"California\", \"Texas\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Entries from an Axis\n",
    "\n",
    "The process of dropping one or more entries from an axis in pandas is straightforward, whether you're dealing with a Series or a DataFrame. If you already possess an index array or list without the entries you want to drop, you can utilize either the `reindex` method or `.loc`-based indexing. However, to streamline this process and avoid the complexities of set logic and manipulation, pandas offers the `drop` method, which conveniently returns a new object with the specified value or values removed from an axis.\n",
    "\n",
    "**Dropping Entries from a Series:**\n",
    "\n",
    "Let's begin with dropping entries from a Series. Consider the following example:\n",
    "\n",
    "```python\n",
    "obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "```\n",
    "\n",
    "You can drop a single entry by providing its label to the `drop` method:\n",
    "\n",
    "```python\n",
    "new_obj = obj.drop(\"c\")\n",
    "```\n",
    "\n",
    "Or drop multiple entries by passing a list of labels:\n",
    "\n",
    "```python\n",
    "obj.drop([\"d\", \"c\"])\n",
    "```\n",
    "\n",
    "**Dropping Entries from a DataFrame:**\n",
    "\n",
    "In a DataFrame, you can drop index values from either axis. First, let's create an example DataFrame:\n",
    "\n",
    "```python\n",
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "```\n",
    "\n",
    "To drop values from the row labels (axis 0), use the `drop` method with the `index` keyword:\n",
    "\n",
    "```python\n",
    "data.drop(index=[\"Colorado\", \"Ohio\"])\n",
    "```\n",
    "\n",
    "To drop labels from the columns, utilize the `columns` keyword:\n",
    "\n",
    "```python\n",
    "data.drop(columns=[\"two\"])\n",
    "```\n",
    "\n",
    "Alternatively, you can drop values from the columns by specifying `axis=1` or `axis=\"columns\"`:\n",
    "\n",
    "```python\n",
    "data.drop(\"two\", axis=1)\n",
    "data.drop([\"two\", \"four\"], axis=\"columns\")\n",
    "```\n",
    "\n",
    "In summary, the `drop` method provides a convenient way to remove specified values from either the row or column axis in pandas Series and DataFrames, making data manipulation tasks more efficient and intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "obj\n",
    "new_obj = obj.drop(\"c\")\n",
    "new_obj\n",
    "obj.drop([\"d\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=[\"Colorado\", \"Ohio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"two\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"two\", axis=1)\n",
    "data.drop([\"two\", \"four\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing, Selection, and Filtering\n",
    "\n",
    "In pandas, Series indexing (`obj[...]`) operates similarly to NumPy array indexing. However, it introduces the ability to utilize the Series's index values instead of just integers. Here are some examples illustrating this:\n",
    "\n",
    "```python\n",
    "obj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "obj[\"b\"]        # Selecting by label\n",
    "obj[1]          # Selecting by integer position\n",
    "obj[2:4]        # Slicing by integer positions\n",
    "obj[[\"b\", \"a\", \"d\"]]   # Selecting multiple labels\n",
    "obj[[1, 3]]     # Selecting multiple integer positions\n",
    "obj[obj < 2]    # Selecting by boolean indexing\n",
    "```\n",
    "\n",
    "While using label-based selection with `[]` is possible, the preferred method is using the `loc` operator:\n",
    "\n",
    "```python\n",
    "obj.loc[[\"b\", \"a\", \"d\"]]\n",
    "```\n",
    "\n",
    "The distinction lies in the treatment of integers when indexing with `[]`. Regular `[]` indexing treats integers as labels if the index contains integers. To address this inconsistency, pandas offers the `iloc` operator for integer-based indexing:\n",
    "\n",
    "```python\n",
    "obj1 = pd.Series([1, 2, 3], index=[2, 0, 1])\n",
    "obj1.iloc[[0, 1, 2]]\n",
    "```\n",
    "\n",
    "When using `loc`, it indexes exclusively with labels, ensuring consistency irrespective of the index's data type.\n",
    "\n",
    "**Caution:**\n",
    "Using regular `[]`-based indexing with labels may result in unexpected behavior due to the treatment of integers as labels when the index contains integers.\n",
    "\n",
    "For DataFrame indexing, you can retrieve one or more columns using a single value or sequence:\n",
    "\n",
    "```python\n",
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "\n",
    "data[\"two\"]    # Retrieving a single column\n",
    "data[[\"three\", \"one\"]]   # Retrieving multiple columns\n",
    "```\n",
    "\n",
    "Indexing with a Boolean array or DataFrame is another common use case. For instance, you can use a Boolean array to select rows or columns based on a condition:\n",
    "\n",
    "```python\n",
    "data[:2]    # Selecting rows with slicing\n",
    "data[data[\"three\"] > 5]    # Selecting rows based on a condition\n",
    "```\n",
    "\n",
    "Moreover, you can use a Boolean DataFrame to assign values to specific locations in the DataFrame:\n",
    "\n",
    "```python\n",
    "data[data < 5] = 0    # Assigning values based on a condition\n",
    "```\n",
    "\n",
    "In summary, pandas offers versatile methods for indexing, selection, and filtering, allowing for efficient and intuitive data manipulation in Series and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "obj\n",
    "obj[\"b\"]\n",
    "obj[1]\n",
    "obj[2:4]\n",
    "obj[[\"b\", \"a\", \"d\"]]\n",
    "obj[[1, 3]]\n",
    "obj[obj < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.loc[[\"b\", \"a\", \"d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1 = pd.Series([1, 2, 3], index=[2, 0, 1])\n",
    "obj2 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
    "obj1\n",
    "obj2\n",
    "obj1[[0, 1, 2]]\n",
    "obj2[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1.iloc[[0, 1, 2]]\n",
    "obj2.iloc[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.loc[\"b\":\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.loc[\"b\":\"c\"] = 5\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n",
    "                    index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n",
    "                    columns=[\"one\", \"two\", \"three\", \"four\"])\n",
    "data\n",
    "data[\"two\"]\n",
    "data[[\"three\", \"one\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:2]\n",
    "data[data[\"three\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data < 5] = 0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection on DataFrame with loc and iloc\n",
    "\n",
    "In pandas, DataFrame objects have two key attributes for indexing: `loc` and `iloc`, which stand for label-based and integer-based indexing, respectively. Since a DataFrame is two-dimensional, you can use these attributes to select subsets of rows and columns using either axis labels (`loc`) or integers (`iloc`), similar to how you would with NumPy arrays.\n",
    "\n",
    "**Using loc:**\n",
    "\n",
    "To illustrate, let's start by selecting a single row by its label:\n",
    "\n",
    "```python\n",
    "data.loc[\"Colorado\"]\n",
    "```\n",
    "\n",
    "This returns a Series object with the column labels of the DataFrame as its index. To select multiple rows and create a new DataFrame, you can pass a sequence of labels:\n",
    "\n",
    "```python\n",
    "data.loc[[\"Colorado\", \"New York\"]]\n",
    "```\n",
    "\n",
    "You can combine row and column selection using `loc` by separating them with a comma:\n",
    "\n",
    "```python\n",
    "data.loc[\"Colorado\", [\"two\", \"three\"]]\n",
    "```\n",
    "\n",
    "**Using iloc:**\n",
    "\n",
    "For integer-based indexing, you can use `iloc`. For instance, to select the third row:\n",
    "\n",
    "```python\n",
    "data.iloc[2]\n",
    "```\n",
    "\n",
    "To select multiple rows or columns, provide a list of integers:\n",
    "\n",
    "```python\n",
    "data.iloc[[2, 1]]\n",
    "data.iloc[2, [3, 0, 1]]\n",
    "```\n",
    "\n",
    "**Slicing:**\n",
    "\n",
    "Both `loc` and `iloc` support slicing. For example, to select rows up to and including \"Utah\":\n",
    "\n",
    "```python\n",
    "data.loc[:\"Utah\", \"two\"]\n",
    "```\n",
    "\n",
    "You can also perform boolean indexing with `loc`, but not with `iloc`:\n",
    "\n",
    "```python\n",
    "data.loc[data.three >= 2]\n",
    "```\n",
    "\n",
    "**Summary of DataFrame Indexing Options:**\n",
    "\n",
    "There are many ways to select and rearrange data in a pandas DataFrame. Table 5.4 provides a concise summary of these options:\n",
    "\n",
    "- `df[column]`: Selects a single column or sequence of columns from the DataFrame. It also supports conveniences like boolean arrays, slices, or boolean DataFrames.\n",
    "- `df.loc[rows]`: Selects a single row or subset of rows from the DataFrame by label.\n",
    "- `df.loc[:, cols]`: Selects a single column or subset of columns by label.\n",
    "- `df.loc[rows, cols]`: Selects both rows and columns by label.\n",
    "- `df.iloc[rows]`: Selects a single row or subset of rows from the DataFrame by integer position.\n",
    "- `df.iloc[:, cols]`: Selects a single column or subset of columns by integer position.\n",
    "- `df.iloc[rows, cols]`: Selects both rows and columns by integer position.\n",
    "- `df.at[row, col]`: Selects a single scalar value by row and column label.\n",
    "- `df.iat[row, col]`: Selects a single scalar value by row and column position (integers).\n",
    "- `reindex` method: Selects either rows or columns by labels.\n",
    "\n",
    "Understanding these indexing options allows for versatile and efficient data manipulation in pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "data.loc[\"Colorado\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[[\"Colorado\", \"New York\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"Colorado\", [\"two\", \"three\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2]\n",
    "data.iloc[[2, 1]]\n",
    "data.iloc[2, [3, 0, 1]]\n",
    "data.iloc[[1, 2], [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:\"Utah\", \"two\"]\n",
    "data.iloc[:, :3][data.three > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.three >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential Issues with Integer Indexing\n",
    "\n",
    "When working with pandas objects that are indexed by integers, it's important to be aware of potential pitfalls, especially for new users. Unlike built-in Python data structures such as lists and tuples, integer indexing in pandas operates differently and can lead to unexpected errors.\n",
    "\n",
    "Let's consider an example with a pandas Series:\n",
    "\n",
    "```python\n",
    "ser = pd.Series(np.arange(3.))\n",
    "```\n",
    "\n",
    "Printing `ser` shows:\n",
    "\n",
    "```\n",
    "0    0.0\n",
    "1    1.0\n",
    "2    2.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Now, if we try to access an element using a negative integer index, like `-1`, which would typically retrieve the last element in a list or tuple, pandas raises an error:\n",
    "\n",
    "```python\n",
    "ser[-1]\n",
    "```\n",
    "\n",
    "The error message indicates a `KeyError`:\n",
    "\n",
    "```\n",
    "KeyError: -1\n",
    "```\n",
    "\n",
    "Pandas doesn't \"fall back\" on integer indexing in this case because it's challenging to do so without introducing subtle bugs into the code. The index in this Series contains `0`, `1`, and `2`, but pandas doesn't want to make assumptions about whether the user intends label-based indexing or position-based indexing.\n",
    "\n",
    "However, with a non-integer index, such as strings, there's no ambiguity:\n",
    "\n",
    "```python\n",
    "ser2 = pd.Series(np.arange(3.), index=[\"a\", \"b\", \"c\"])\n",
    "ser2[-1]  # This returns 2.0 without error\n",
    "```\n",
    "\n",
    "In situations where the index contains integers, it's best to use `loc` (for labels) or `iloc` (for integers) to ensure clear and unambiguous data selection:\n",
    "\n",
    "```python\n",
    "ser.iloc[-1]  # This retrieves the last element\n",
    "```\n",
    "\n",
    "Similarly, slicing with integers is always integer-oriented:\n",
    "\n",
    "```python\n",
    "ser[:2]  # This returns the first two elements\n",
    "```\n",
    "\n",
    "To avoid potential issues and ensure clarity in your code, it's advisable to consistently use `loc` and `iloc` for indexing pandas objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(3.))\n",
    "ser\n",
    "ser[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2 = pd.Series(np.arange(3.), index=[\"a\", \"b\", \"c\"])\n",
    "ser2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pitfalls of Chained Indexing\n",
    "\n",
    "In the previous section, we explored how `loc` and `iloc` can be used for flexible selections on a DataFrame. While these indexing attributes are powerful, using them to modify DataFrame objects in place requires careful attention to avoid potential pitfalls.\n",
    "\n",
    "For instance, let's consider the example DataFrame:\n",
    "\n",
    "```python\n",
    "data.loc[:, \"one\"] = 1\n",
    "data.iloc[2] = 5\n",
    "data.loc[data[\"four\"] > 5] = 3\n",
    "```\n",
    "\n",
    "Here, we are assigning values to columns or rows by label or integer position. These operations modify the DataFrame as expected.\n",
    "\n",
    "However, a common mistake among new pandas users is to chain selections when performing assignments:\n",
    "\n",
    "```python\n",
    "data.loc[data.three == 5][\"three\"] = 6\n",
    "```\n",
    "\n",
    "When executed, this might raise a `SettingWithCopyWarning`, which indicates that a value is trying to be set on a copy of a slice from the DataFrame, rather than the original DataFrame itself. This warning alerts you that you might unintentionally modify a temporary view of the data instead of the original DataFrame.\n",
    "\n",
    "To resolve this issue and ensure that modifications are made to the original DataFrame, it's recommended to rewrite the assignment using a single `loc` operation:\n",
    "\n",
    "```python\n",
    "data.loc[data.three == 5, \"three\"] = 6\n",
    "```\n",
    "\n",
    "This approach ensures that the assignment is performed directly on the original DataFrame.\n",
    "\n",
    "As a general rule, it's advisable to avoid chained indexing when performing assignments in pandas. Chained indexing can lead to unexpected behavior and potentially generate warnings like `SettingWithCopyWarning`. For more information and examples, you can refer to the relevant topic in the online pandas documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, \"one\"] = 1\n",
    "data\n",
    "data.iloc[2] = 5\n",
    "data\n",
    "data.loc[data[\"four\"] > 5] = 3\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.three == 5][\"three\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.three == 5, \"three\"] = 6\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic and Data Alignment\n",
    "\n",
    "Arithmetic operations in pandas involve data alignment, which can simplify working with objects having different indexes. When adding objects, if any index pairs do not match, the resulting index will be the union of these index pairs.\n",
    "\n",
    "For instance, consider two Series objects:\n",
    "\n",
    "```python\n",
    "s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\n",
    "s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\n",
    "```\n",
    "\n",
    "Adding these two Series together:\n",
    "\n",
    "```python\n",
    "s1 + s2\n",
    "```\n",
    "\n",
    "Results in:\n",
    "\n",
    "```\n",
    "a    5.2\n",
    "c    1.1\n",
    "d    NaN\n",
    "e    0.0\n",
    "f    NaN\n",
    "g    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "In this result, the index \"d\" exists only in `s1`, \"f\" and \"g\" only in `s2`, leading to NaN values.\n",
    "\n",
    "Similarly, for DataFrame objects, alignment occurs on both rows and columns. If DataFrame objects have non-matching row or column labels, the result will contain NaN values in those locations.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list(\"bcd\"), index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list(\"bde\"), index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "```\n",
    "\n",
    "Adding these DataFrames:\n",
    "\n",
    "```python\n",
    "df1 + df2\n",
    "```\n",
    "\n",
    "Produces:\n",
    "\n",
    "```\n",
    "            b   c     d   e\n",
    "Colorado  NaN NaN   NaN NaN\n",
    "Ohio      3.0 NaN   6.0 NaN\n",
    "Oregon    NaN NaN   NaN NaN\n",
    "Texas     9.0 NaN  12.0 NaN\n",
    "Utah      NaN NaN   NaN NaN\n",
    "```\n",
    "\n",
    "Here, columns \"c\" and \"e\" are not found in both DataFrames, resulting in NaN values in the respective columns.\n",
    "\n",
    "To handle missing values, you can use arithmetic methods with fill values. For instance, `df1.add(df2, fill_value=0)` will substitute 0 for any missing values during the operation.\n",
    "\n",
    "Additionally, pandas provides flexible arithmetic methods like add, sub, div, mul, etc., each with a counterpart starting with \"r\" that reverses the arguments. For example, `1 / df1` is equivalent to `df1.rdiv(1)`.\n",
    "\n",
    "When reindexing a Series or DataFrame, you can specify a fill value using the `fill_value` parameter. This allows you to replace NaN values with a custom value during the reindexing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -2.1\n",
       "c    3.6\n",
       "e   -1.5\n",
       "f    4.0\n",
       "g    3.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\n",
    "s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1],\n",
    "               index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\n",
    "s1\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list(\"bcd\"),\n",
    "                   index=[\"Ohio\", \"Texas\", \"Colorado\"])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list(\"bde\"),\n",
    "                   index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "df1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding DataFrame objects with no common column or row labels, the resulting DataFrame will contain all null values:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\"A\": [1, 2]})\n",
    "df2 = pd.DataFrame({\"B\": [3, 4]})\n",
    "\n",
    "df1 + df2\n",
    "```\n",
    "\n",
    "This produces:\n",
    "\n",
    "```\n",
    "    A   B\n",
    "0 NaN NaN\n",
    "1 NaN NaN\n",
    "```\n",
    "\n",
    "Both rows and columns contain only NaN values since there are no overlapping labels.\n",
    "\n",
    "In arithmetic operations between differently indexed objects, you may want to fill missing values with a special value, such as 0. Here's an example where we replace missing values with NaN:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list(\"abcd\"))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list(\"abcde\"))\n",
    "\n",
    "df2.loc[1, \"b\"] = np.nan\n",
    "\n",
    "df1 + df2\n",
    "```\n",
    "\n",
    "The result is:\n",
    "\n",
    "```\n",
    "      a     b     c     d   e\n",
    "0   0.0   2.0   4.0   6.0 NaN\n",
    "1   9.0   NaN  13.0  15.0 NaN\n",
    "2  18.0  20.0  22.0  24.0 NaN\n",
    "3   NaN   NaN   NaN   NaN NaN\n",
    "```\n",
    "\n",
    "Here, missing values occur in locations where indexes dont overlap. To replace missing values with a specific value, such as 0, you can use the `add` method with the `fill_value` argument:\n",
    "\n",
    "```python\n",
    "df1.add(df2, fill_value=0)\n",
    "```\n",
    "\n",
    "This yields:\n",
    "\n",
    "```\n",
    "      a     b     c     d     e\n",
    "0   0.0   2.0   4.0   6.0   4.0\n",
    "1   9.0   5.0  13.0  15.0   9.0\n",
    "2  18.0  20.0  22.0  24.0  14.0\n",
    "3  15.0  16.0  17.0  18.0  19.0\n",
    "```\n",
    "\n",
    "All missing values have been filled with 0, providing a more structured result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"A\": [1, 2]})\n",
    "df2 = pd.DataFrame({\"B\": [3, 4]})\n",
    "df1\n",
    "df2\n",
    "df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),\n",
    "                   columns=list(\"abcd\"))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),\n",
    "                   columns=list(\"abcde\"))\n",
    "df2.loc[1, \"b\"] = np.nan\n",
    "df1\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table provides a summary of flexible arithmetic methods available for both Series and DataFrame objects in pandas, along with their descriptions:\n",
    "\n",
    "| Method      | Description                                    |\n",
    "|-------------|------------------------------------------------|\n",
    "| add, radd   | Methods for addition (+)                       |\n",
    "| sub, rsub   | Methods for subtraction (-)                    |\n",
    "| div, rdiv   | Methods for division (/)                       |\n",
    "| floordiv, rfloordiv | Methods for floor division (//)         |\n",
    "| mul, rmul   | Methods for multiplication (*)                 |\n",
    "| pow, rpow   | Methods for exponentiation (**)                |\n",
    "\n",
    "These methods offer versatile ways to perform arithmetic operations and handle missing or differently indexed data.\n",
    "\n",
    "For instance, when dividing 1 by a DataFrame `df1`, you can use either the `/` operator or the `div` method. The `rdiv` method performs the same operation but with reversed arguments:\n",
    "\n",
    "```python\n",
    "1 / df1\n",
    "df1.rdiv(1)\n",
    "```\n",
    "\n",
    "Both yield the same result, where each element in `df1` is divided into 1. This is particularly useful when dealing with numerical data and performing element-wise operations.\n",
    "\n",
    "Similarly, when reindexing a DataFrame `df1` with columns from another DataFrame `df2`, you can specify a fill value to replace missing entries using the `fill_value` parameter in the `reindex` method:\n",
    "\n",
    "```python\n",
    "df1.reindex(columns=df2.columns, fill_value=0)\n",
    "```\n",
    "\n",
    "This ensures that any missing columns in `df1` are filled with the specified value (in this case, 0), providing a more structured output.\n",
    "\n",
    "In summary, these flexible arithmetic methods in pandas offer convenient ways to manipulate data, handle missing values, and perform various mathematical operations efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / df1\n",
    "df1.rdiv(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reindex(columns=df2.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations between DataFrame and Series\n",
    "\n",
    "The example demonstrates the operation between a two-dimensional NumPy array (`arr`) and one of its rows. The row-wise subtraction of `arr[0]` from `arr` results in subtracting each element of the first row of `arr` from corresponding elements in each row of `arr`. Here's a breakdown:\n",
    "\n",
    "1. We initialize a two-dimensional NumPy array `arr`:\n",
    "\n",
    "```python\n",
    "arr = np.arange(12.).reshape((3, 4))\n",
    "```\n",
    "\n",
    "This creates a 3x4 array:\n",
    "\n",
    "```\n",
    "array([[ 0.,  1.,  2.,  3.],\n",
    "       [ 4.,  5.,  6.,  7.],\n",
    "       [ 8.,  9., 10., 11.]])\n",
    "```\n",
    "\n",
    "2. Accessing the first row of `arr`:\n",
    "\n",
    "```python\n",
    "arr[0]\n",
    "```\n",
    "\n",
    "This retrieves the first row:\n",
    "\n",
    "```\n",
    "array([0., 1., 2., 3.])\n",
    "```\n",
    "\n",
    "3. Subtracting `arr[0]` from `arr`:\n",
    "\n",
    "```python\n",
    "arr - arr[0]\n",
    "```\n",
    "\n",
    "This operation subtracts each element of the first row of `arr` from corresponding elements in each row of `arr`. The result is:\n",
    "\n",
    "```\n",
    "array([[0., 0., 0., 0.],\n",
    "       [4., 4., 4., 4.],\n",
    "       [8., 8., 8., 8.]])\n",
    "```\n",
    "\n",
    "In summary, performing arithmetic operations between a DataFrame and a Series in pandas follows a similar concept, where operations are broadcasted over rows or columns depending on the axis of the Series. This enables efficient element-wise operations between DataFrames and Series, similar to operations between NumPy arrays of different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(12.).reshape((3, 4))\n",
    "arr\n",
    "arr[0]\n",
    "arr - arr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations involving a DataFrame and a Series are akin:\n",
    "\n",
    "```\n",
    "frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "\n",
    "series = frame.iloc[0]\n",
    "```\n",
    "\n",
    "Consider the DataFrame `frame`:\n",
    "\n",
    "```\n",
    "          b     d     e\n",
    "Utah    0.0   1.0   2.0\n",
    "Ohio    3.0   4.0   5.0\n",
    "Texas   6.0   7.0   8.0\n",
    "Oregon  9.0  10.0  11.0\n",
    "```\n",
    "\n",
    "And the Series `series`:\n",
    "\n",
    "```\n",
    "b    0.0\n",
    "d    1.0\n",
    "e    2.0\n",
    "Name: Utah, dtype: float64\n",
    "```\n",
    "\n",
    "The default arithmetic operation between a DataFrame and a Series aligns the Series index with the DataFrame columns, propagating the operation along the rows:\n",
    "\n",
    "```\n",
    "frame - series\n",
    "```\n",
    "\n",
    "This yields:\n",
    "\n",
    "```\n",
    "          b    d    e\n",
    "Utah    0.0  0.0  0.0\n",
    "Ohio    3.0  3.0  3.0\n",
    "Texas   6.0  6.0  6.0\n",
    "Oregon  9.0  9.0  9.0\n",
    "```\n",
    "\n",
    "If an index value is absent in either the DataFrame's columns or the Series's index, the objects are reindexed to encompass the union:\n",
    "\n",
    "```\n",
    "series2 = pd.Series(np.arange(3), index=[\"b\", \"e\", \"f\"])\n",
    "\n",
    "frame + series2\n",
    "```\n",
    "\n",
    "Resulting in:\n",
    "\n",
    "```\n",
    "          b   d     e   f\n",
    "Utah    0.0 NaN   3.0 NaN\n",
    "Ohio    3.0 NaN   6.0 NaN\n",
    "Texas   6.0 NaN   9.0 NaN\n",
    "Oregon  9.0 NaN  12.0 NaN\n",
    "``` \n",
    "\n",
    "Here, the `f` index from `series2` is absent in `frame`, thus resulting in `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "series = frame.iloc[0]\n",
    "frame\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame - series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series(np.arange(3), index=[\"b\", \"e\", \"f\"])\n",
    "series2\n",
    "frame + series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aim to perform broadcasting over the columns, aligning operations on the rows, you need to utilize one of the arithmetic methods while specifying to align over the index. For instance:\n",
    "\n",
    "```python\n",
    "series3 = frame[\"d\"]\n",
    "\n",
    "frame\n",
    "```\n",
    "Produces:\n",
    "```\n",
    "          b     d     e\n",
    "Utah    0.0   1.0   2.0\n",
    "Ohio    3.0   4.0   5.0\n",
    "Texas   6.0   7.0   8.0\n",
    "Oregon  9.0  10.0  11.0\n",
    "```\n",
    "\n",
    "And the Series `series3`:\n",
    "```\n",
    "Utah       1.0\n",
    "Ohio       4.0\n",
    "Texas      7.0\n",
    "Oregon    10.0\n",
    "Name: d, dtype: float64\n",
    "```\n",
    "\n",
    "To perform subtraction while broadcasting across the columns, aligning over the DataFrame's row index, use `sub` method specifying `axis=\"index\"`:\n",
    "\n",
    "```python\n",
    "frame.sub(series3, axis=\"index\")\n",
    "```\n",
    "\n",
    "This results in:\n",
    "```\n",
    "          b    d    e\n",
    "Utah   -1.0  0.0  1.0\n",
    "Ohio   -1.0  0.0  1.0\n",
    "Texas  -1.0  0.0  1.0\n",
    "Oregon -1.0  0.0  1.0\n",
    "```\n",
    "\n",
    "Here, the specified axis (`axis=\"index\"`) indicates alignment over the DataFrame's row index, thus broadcasting the operation across the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "series3 = frame[\"d\"]\n",
    "frame\n",
    "series3\n",
    "frame.sub(series3, axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Application and Mapping\n",
    "\n",
    "Numpy's universal functions (ufuncs), which are element-wise array methods, are also compatible with pandas objects:\n",
    "\n",
    "```python\n",
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "\n",
    "frame\n",
    "```\n",
    "This generates:\n",
    "```\n",
    "               b         d         e\n",
    "Utah   -0.204708  0.478943 -0.519439\n",
    "Ohio   -0.555730  1.965781  1.393406\n",
    "Texas   0.092908  0.281746  0.769023\n",
    "Oregon  1.246435  1.007189 -1.296221\n",
    "```\n",
    "\n",
    "When applying the absolute function (`np.abs()`), it operates element-wise on the DataFrame:\n",
    "\n",
    "```python\n",
    "np.abs(frame)\n",
    "```\n",
    "\n",
    "Resulting in:\n",
    "```\n",
    "               b         d         e\n",
    "Utah    0.204708  0.478943  0.519439\n",
    "Ohio    0.555730  1.965781  1.393406\n",
    "Texas   0.092908  0.281746  0.769023\n",
    "Oregon  1.246435  1.007189  1.296221\n",
    "```\n",
    "\n",
    "Here, the `np.abs()` function computes the absolute value for each element in the DataFrame `frame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n",
    "                     columns=list(\"bde\"),\n",
    "                     index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "frame\n",
    "np.abs(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "frame.apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.apply(f1, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `apply` method in pandas allows you to apply a function to one-dimensional arrays, either along columns or rows in a DataFrame:\n",
    "\n",
    "```python\n",
    "def f1(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "frame.apply(f1)\n",
    "```\n",
    "\n",
    "This computes the difference between the maximum and minimum values for each column in the DataFrame `frame`, resulting in a Series where the columns of `frame` become the index:\n",
    "```\n",
    "b    1.802165\n",
    "d    1.684034\n",
    "e    2.689627\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "By specifying `axis=\"columns\"`, the function is applied once per row instead of per column, which can be conceptualized as \"applying across the columns\":\n",
    "\n",
    "```python\n",
    "frame.apply(f1, axis=\"columns\")\n",
    "```\n",
    "\n",
    "Resulting in:\n",
    "```\n",
    "Utah      0.998382\n",
    "Ohio      2.521511\n",
    "Texas     0.676115\n",
    "Oregon    2.542656\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Most common array statistics such as sum and mean have direct DataFrame methods, making the use of `apply` unnecessary in those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "frame.apply(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `apply` method in pandas can handle functions that don't necessarily return scalar values; they can also return Series with multiple values:\n",
    "\n",
    "```python\n",
    "def f2(x):\n",
    "    return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n",
    "\n",
    "frame.apply(f2)\n",
    "```\n",
    "\n",
    "This results in:\n",
    "```\n",
    "            b         d         e\n",
    "min -0.555730  0.281746 -1.296221\n",
    "max  1.246435  1.965781  1.393406\n",
    "```\n",
    "\n",
    "Additionally, you can use element-wise Python functions. For instance, suppose you wish to format each floating-point value in `frame` as a string. You can achieve this with `applymap`:\n",
    "\n",
    "```python\n",
    "def my_format(x):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "frame.applymap(my_format)\n",
    "```\n",
    "\n",
    "Resulting in:\n",
    "```\n",
    "            b     d      e\n",
    "Utah    -0.20  0.48  -0.52\n",
    "Ohio    -0.56  1.97   1.39\n",
    "Texas    0.09  0.28   0.77\n",
    "Oregon   1.25  1.01  -1.30\n",
    "```\n",
    "\n",
    "The name `applymap` suggests that it applies an element-wise function across the DataFrame.\n",
    "\n",
    "Moreover, Series objects have a `map` method for applying element-wise functions:\n",
    "\n",
    "```python\n",
    "frame[\"e\"].map(my_format)\n",
    "```\n",
    "\n",
    "Which yields:\n",
    "```\n",
    "Utah      -0.52\n",
    "Ohio       1.39\n",
    "Texas      0.77\n",
    "Oregon    -1.30\n",
    "Name: e, dtype: object\n",
    "```\n",
    "\n",
    "Here, each element in the \"e\" column of the DataFrame `frame` is formatted as a string using the `my_format` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_format(x):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "frame.applymap(my_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"e\"].map(my_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Ranking\n",
    "\n",
    "Sorting a dataset by specific criteria is a fundamental operation in data analysis. In pandas, you can achieve lexicographical sorting by row or column labels using the `sort_index` method, which returns a new sorted object.\n",
    "\n",
    "For instance, with a Series, you can sort it lexicographically by index:\n",
    "\n",
    "```python\n",
    "obj = pd.Series(np.arange(4), index=[\"d\", \"a\", \"b\", \"c\"])\n",
    "obj.sort_index()\n",
    "```\n",
    "This rearranges the Series `obj`:\n",
    "```\n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "d    0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "With a DataFrame, sorting by index can be done on either axis:\n",
    "\n",
    "```python\n",
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                     index=[\"three\", \"one\"],\n",
    "                     columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "frame.sort_index()\n",
    "```\n",
    "Result:\n",
    "```\n",
    "       d  a  b  c\n",
    "one    4  5  6  7\n",
    "three  0  1  2  3\n",
    "```\n",
    "\n",
    "Sorting by index along columns is achieved by specifying `axis=\"columns\"`:\n",
    "\n",
    "```python\n",
    "frame.sort_index(axis=\"columns\")\n",
    "```\n",
    "Output:\n",
    "```\n",
    "       a  b  c  d\n",
    "three  1  2  3  0\n",
    "one    5  6  7  4\n",
    "```\n",
    "\n",
    "By default, the data is sorted in ascending order. However, you can specify `ascending=False` to sort in descending order:\n",
    "\n",
    "```python\n",
    "frame.sort_index(axis=\"columns\", ascending=False)\n",
    "```\n",
    "This yields:\n",
    "```\n",
    "       d  c  b  a\n",
    "three  0  3  2  1\n",
    "one    4  7  6  5\n",
    "```\n",
    "\n",
    "These examples demonstrate how to sort data in pandas using the `sort_index` method along rows or columns, in both ascending and descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(4), index=[\"d\", \"a\", \"b\", \"c\"])\n",
    "obj\n",
    "obj.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                     index=[\"three\", \"one\"],\n",
    "                     columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "frame\n",
    "frame.sort_index()\n",
    "frame.sort_index(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index(axis=\"columns\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort a Series by its values rather than its index, you can use the `sort_values` method:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([4, 7, -3, 2])\n",
    "obj.sort_values()\n",
    "```\n",
    "This sorts the Series `obj` by its values:\n",
    "```\n",
    "2   -3\n",
    "3    2\n",
    "0    4\n",
    "1    7\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "When there are missing values, they are sorted to the end of the Series by default:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "obj.sort_values()\n",
    "```\n",
    "Result:\n",
    "```\n",
    "4   -3.0\n",
    "5    2.0\n",
    "0    4.0\n",
    "2    7.0\n",
    "1    NaN\n",
    "3    NaN\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "However, you can choose to sort missing values to the beginning by specifying the `na_position` option as `\"first\"`:\n",
    "\n",
    "```python\n",
    "obj.sort_values(na_position=\"first\")\n",
    "```\n",
    "Output:\n",
    "```\n",
    "1    NaN\n",
    "3    NaN\n",
    "4   -3.0\n",
    "5    2.0\n",
    "0    4.0\n",
    "2    7.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "This way, missing values will appear at the start of the sorted Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, 7, -3, 2])\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.sort_values(na_position=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When sorting a DataFrame, you can use the data in one or more columns as the sort keys. To do this, you pass one or more column names to the `sort_values` method:\n",
    "\n",
    "```python\n",
    "frame = pd.DataFrame({\"b\": [4, 7, -3, 2], \"a\": [0, 1, 0, 1]})\n",
    "frame.sort_values(\"b\")\n",
    "```\n",
    "This sorts the DataFrame `frame` by the values in the \"b\" column:\n",
    "```\n",
    "   b  a\n",
    "2 -3  0\n",
    "3  2  1\n",
    "0  4  0\n",
    "1  7  1\n",
    "```\n",
    "\n",
    "To sort by multiple columns, you pass a list of column names to `sort_values`:\n",
    "\n",
    "```python\n",
    "frame.sort_values([\"a\", \"b\"])\n",
    "```\n",
    "Result:\n",
    "```\n",
    "   b  a\n",
    "2 -3  0\n",
    "0  4  0\n",
    "3  2  1\n",
    "1  7  1\n",
    "```\n",
    "\n",
    "This sorts the DataFrame first by the values in the \"a\" column, and then within each group of equal \"a\" values, it sorts by the values in the \"b\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4, 7, -3, 2], \"a\": [0, 1, 0, 1]})\n",
    "frame\n",
    "frame.sort_values(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values([\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking\n",
    "\n",
    "Ranking assigns ranks from one through the number of valid data points in an array, starting from the lowest value. The `rank` methods for Series and DataFrame handle this; by default, ties are broken by assigning each group the mean rank:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "obj.rank()\n",
    "```\n",
    "This assigns ranks to the values in the Series `obj`:\n",
    "```\n",
    "0    6.5\n",
    "1    1.0\n",
    "2    6.5\n",
    "3    4.5\n",
    "4    3.0\n",
    "5    2.0\n",
    "6    4.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Ranks can also be assigned based on the order they're observed in the data:\n",
    "\n",
    "```python\n",
    "obj.rank(method=\"first\")\n",
    "```\n",
    "Output:\n",
    "```\n",
    "0    6.0\n",
    "1    1.0\n",
    "2    7.0\n",
    "3    4.0\n",
    "4    3.0\n",
    "5    2.0\n",
    "6    5.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Here, instead of using the average rank (6.5) for the entries 0 and 2, they are set to 6 and 7 because label 0 precedes label 2 in the data.\n",
    "\n",
    "Ranking can also be done in descending order:\n",
    "\n",
    "```python\n",
    "obj.rank(ascending=False)\n",
    "```\n",
    "Result:\n",
    "```\n",
    "0    1.5\n",
    "1    7.0\n",
    "2    1.5\n",
    "3    3.5\n",
    "4    5.0\n",
    "5    6.0\n",
    "6    3.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Refer to Table 5.6 for a list of tie-breaking methods available.\n",
    "\n",
    "Table 5.6: Tie-breaking methods with rank\n",
    "\n",
    "| Method   | Description                                                                                         |\n",
    "|----------|-----------------------------------------------------------------------------------------------------|\n",
    "| \"average\"| Default: assigns the average rank to each entry in the equal group.                                |\n",
    "| \"min\"    | Uses the minimum rank for the whole group.                                                          |\n",
    "| \"max\"    | Uses the maximum rank for the whole group.                                                          |\n",
    "| \"first\"  | Assigns ranks in the order the values appear in the data.                                           |\n",
    "| \"dense\"  | Similar to method=\"min\", but ranks always increase by 1 between groups rather than the number of   |\n",
    "|          | equal elements in a group.                                                                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n",
    "obj.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.rank(method=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.rank(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames can compute ranks over the rows or the columns:\n",
    "\n",
    "```python\n",
    "frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \"a\": [0, 1, 0, 1],\n",
    "                      \"c\": [-2, 5, 8, -2.5]})\n",
    "frame\n",
    "```\n",
    "This DataFrame `frame` is created:\n",
    "```\n",
    "     b  a    c\n",
    "0  4.3  0 -2.0\n",
    "1  7.0  1  5.0\n",
    "2 -3.0  0  8.0\n",
    "3  2.0  1 -2.5\n",
    "```\n",
    "\n",
    "To compute ranks over the columns, you can use the `rank` method with `axis=\"columns\"`:\n",
    "\n",
    "```python\n",
    "frame.rank(axis=\"columns\")\n",
    "```\n",
    "This generates ranks over the columns for each row:\n",
    "```\n",
    "     b    a    c\n",
    "0  3.0  2.0  1.0\n",
    "1  3.0  1.0  2.0\n",
    "2  1.0  2.0  3.0\n",
    "3  3.0  2.0  1.0\n",
    "```\n",
    "\n",
    "Each value represents the rank of the corresponding element within its row, where ties are broken by the order of appearance in the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \"a\": [0, 1, 0, 1],\n",
    "                      \"c\": [-2, 5, 8, -2.5]})\n",
    "frame\n",
    "frame.rank(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axis Indexes with Duplicate Labels\n",
    "\n",
    "Up until now, most examples we've seen had unique axis labels (index values). While many pandas functions, like `reindex`, require unique labels, it's not mandatory. Let's explore a small Series with duplicate indices:\n",
    "\n",
    "```python\n",
    "obj = pd.Series(np.arange(5), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "obj\n",
    "```\n",
    "This Series `obj` has duplicate indices:\n",
    "```\n",
    "a    0\n",
    "a    1\n",
    "b    2\n",
    "b    3\n",
    "c    4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "The `is_unique` property of the index can inform you whether its labels are unique:\n",
    "\n",
    "```python\n",
    "obj.index.is_unique\n",
    "```\n",
    "Result:\n",
    "```\n",
    "False\n",
    "```\n",
    "\n",
    "Data selection behaves differently with duplicates. Indexing a label with multiple entries returns a Series, while single entries return a scalar value:\n",
    "\n",
    "```python\n",
    "obj[\"a\"]\n",
    "```\n",
    "Output:\n",
    "```\n",
    "a    0\n",
    "a    1\n",
    "dtype: int64\n",
    "\n",
    "obj[\"c\"]\n",
    "```\n",
    "Output:\n",
    "```\n",
    "4\n",
    "```\n",
    "\n",
    "This variability in output types based on label repetition can complicate your code.\n",
    "\n",
    "The same behavior extends to indexing rows (or columns) in a DataFrame:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(np.random.standard_normal((5, 3)),\n",
    "                  index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "df\n",
    "```\n",
    "Result:\n",
    "```\n",
    "          0         1         2\n",
    "a  0.274992  0.228913  1.352917\n",
    "a  0.886429 -2.001637 -0.371843\n",
    "b  1.669025 -0.438570 -0.539741\n",
    "b  0.476985  3.248944 -1.021228\n",
    "c -0.577087  0.124121  0.302614\n",
    "```\n",
    "\n",
    "Indexing rows with duplicated labels returns a DataFrame:\n",
    "\n",
    "```python\n",
    "df.loc[\"b\"]\n",
    "```\n",
    "Result:\n",
    "```\n",
    "          0         1         2\n",
    "b  1.669025 -0.438570 -0.539741\n",
    "b  0.476985  3.248944 -1.021228\n",
    "```\n",
    "\n",
    "But when the label is unique, it returns a Series:\n",
    "\n",
    "```python\n",
    "df.loc[\"c\"]\n",
    "```\n",
    "Result:\n",
    "```\n",
    "0   -0.577087\n",
    "1    0.124121\n",
    "2    0.302614\n",
    "Name: c, dtype: float64\n",
    "```\n",
    "\n",
    "This behavior highlights the importance of handling duplicate labels appropriately in your data analysis workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(np.arange(5), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj[\"a\"]\n",
    "obj[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.standard_normal((5, 3)),\n",
    "                  index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n",
    "df\n",
    "df.loc[\"b\"]\n",
    "df.loc[\"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Summarizing and Computing Descriptive Statistics\n",
    "\n",
    "Pandas objects come with a variety of mathematical and statistical methods, mostly falling into the category of reductions or summary statistics. These methods extract a single value (like the sum or mean) from a Series or a Series of values from the rows or columns of a DataFrame. Compared to similar methods found on NumPy arrays, pandas methods have built-in handling for missing data. Let's explore these using a small DataFrame:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n",
    "                   [np.nan, np.nan], [0.75, -1.3]],\n",
    "                  index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "                  columns=[\"one\", \"two\"])\n",
    "df\n",
    "```\n",
    "This DataFrame `df` contains some NaN values:\n",
    "```\n",
    "    one  two\n",
    "a  1.40  NaN\n",
    "b  7.10 -4.5\n",
    "c   NaN  NaN\n",
    "d  0.75 -1.3\n",
    "```\n",
    "\n",
    "Calling DataFrame's `sum` method returns a Series containing column sums:\n",
    "\n",
    "```python\n",
    "df.sum()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "one    9.25\n",
    "two   -5.80\n",
    "dtype: float64\n",
    "\n",
    "Passing `axis=\"columns\"` or `axis=1` sums across the columns instead:\n",
    "\n",
    "```python\n",
    "df.sum(axis=\"columns\")\n",
    "```\n",
    "Output:\n",
    "```\n",
    "a    1.40\n",
    "b    2.60\n",
    "c    0.00\n",
    "d   -0.55\n",
    "dtype: float64\n",
    "\n",
    "When an entire row or column contains all NA values, the sum is 0. If any value is not NA, then the result is NA. This behavior can be changed with the `skipna` option:\n",
    "\n",
    "```python\n",
    "df.sum(axis=\"index\", skipna=False)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "one   NaN\n",
    "two   NaN\n",
    "dtype: float64\n",
    "\n",
    "```python\n",
    "df.sum(axis=\"columns\", skipna=False)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "a     NaN\n",
    "b    2.60\n",
    "c     NaN\n",
    "d   -0.55\n",
    "dtype: float64\n",
    "\n",
    "Some aggregations, like `mean`, require at least one non-NA value to yield a valid result:\n",
    "\n",
    "```python\n",
    "df.mean(axis=\"columns\")\n",
    "```\n",
    "Output:\n",
    "```\n",
    "a    1.400\n",
    "b    1.300\n",
    "c      NaN\n",
    "d   -0.275\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Refer to Table 5.7 for a list of common options available for each reduction method.\n",
    "\n",
    "Here's Table 5.7 with options for reduction methods:\n",
    "\n",
    "| Method | Description                                                                                           |\n",
    "|--------|-------------------------------------------------------------------------------------------------------|\n",
    "| axis   | Axis to reduce over; \"index\" for DataFrame's rows and \"columns\" for columns                           |\n",
    "| skipna | Exclude missing values; True by default                                                               |\n",
    "| level  | Reduce grouped by level if the axis is hierarchically indexed (MultiIndex)                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n",
    "                   [np.nan, np.nan], [0.75, -1.3]],\n",
    "                  index=[\"a\", \"b\", \"c\", \"d\"],\n",
    "                  columns=[\"one\", \"two\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=\"index\", skipna=False)\n",
    "df.sum(axis=\"columns\", skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some methods in pandas, like `idxmin` and `idxmax`, return indirect statistics, providing the index value where the minimum or maximum values are attained:\n",
    "\n",
    "```python\n",
    "df.idxmax()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "one    b\n",
    "two    d\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "Other methods, such as `cumsum`, perform accumulations:\n",
    "\n",
    "```python\n",
    "df.cumsum()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "    one  two\n",
    "a  1.40  NaN\n",
    "b  8.50 -4.5\n",
    "c   NaN  NaN\n",
    "d  9.25 -5.8\n",
    "```\n",
    "\n",
    "Some methods neither reduce nor accumulate. `describe` is one such example, producing multiple summary statistics in one shot:\n",
    "\n",
    "```python\n",
    "df.describe()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "            one       two\n",
    "count  3.000000  2.000000\n",
    "mean   3.083333 -2.900000\n",
    "std    3.493685  2.262742\n",
    "min    0.750000 -4.500000\n",
    "25%    1.075000 -3.700000\n",
    "50%    1.400000 -2.900000\n",
    "75%    4.250000 -2.100000\n",
    "max    7.100000 -1.300000\n",
    "```\n",
    "\n",
    "On non-numeric data, `describe` produces alternative summary statistics:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)\n",
    "obj.describe()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "count     16\n",
    "unique     3\n",
    "top        a\n",
    "freq       8\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "These methods provide various ways to summarize and analyze your data efficiently.\n",
    "\n",
    "Here's Table 5.8 with a full list of descriptive and summary statistics methods and their descriptions:\n",
    "\n",
    "| Method      | Description                                                                                        |\n",
    "|-------------|----------------------------------------------------------------------------------------------------|\n",
    "| count       | Number of non-NA values                                                                            |\n",
    "| describe    | Compute a set of summary statistics                                                                |\n",
    "| min, max    | Compute the minimum and maximum values                                                             |\n",
    "| argmin, argmax | Compute the index locations (integers) at which the minimum or maximum value is obtained, respectively; not available on DataFrame objects |\n",
    "| idxmin, idxmax | Compute the index labels at which the minimum or maximum value is obtained                       |\n",
    "| quantile    | Compute a sample quantile ranging from 0 to 1 (default: 0.5)                                        |\n",
    "| sum         | Sum of values                                                                                      |\n",
    "| mean        | Mean of values                                                                                    |\n",
    "| median      | Arithmetic median (50% quantile) of values                                                        |\n",
    "| mad         | Mean absolute deviation from the mean value                                                        |\n",
    "| prod        | Product of all values                                                                             |\n",
    "| var         | Sample variance of values                                                                         |\n",
    "| std         | Sample standard deviation of values                                                                |\n",
    "| skew        | Sample skewness (third moment) of values                                                           |\n",
    "| kurt        | Sample kurtosis (fourth moment) of values                                                          |\n",
    "| cumsum      | Cumulative sum of values                                                                          |\n",
    "| cummin, cummax | Cumulative minimum or maximum of values, respectively                                             |\n",
    "| cumprod     | Cumulative product of values                                                                      |\n",
    "| diff        | Compute the first arithmetic difference (useful for time series)                                   |\n",
    "| pct_change  | Compute percent changes                                                                           |\n",
    "\n",
    "These methods provide a comprehensive set of tools for analyzing and summarizing data in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)\n",
    "obj.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation and Covariance\n",
    "\n",
    "Certain summary statistics, such as correlation and covariance, require data pairs for computation. Let's consider DataFrames representing stock prices and volumes sourced from Yahoo! Finance and stored in binary Python pickle files.\n",
    "\n",
    "```python\n",
    "price = pd.read_pickle(\"examples/yahoo_price.pkl\")\n",
    "volume = pd.read_pickle(\"examples/yahoo_volume.pkl\")\n",
    "```\n",
    "\n",
    "Next, let's compute the percent changes in prices, a time series operation that will be explored further in Chapter 11:\n",
    "\n",
    "```python\n",
    "returns = price.pct_change()\n",
    "```\n",
    "\n",
    "Here's a snippet of the resulting DataFrame:\n",
    "\n",
    "```\n",
    "                AAPL      GOOG       IBM      MSFT\n",
    "Date                                              \n",
    "2016-10-17 -0.000680  0.001837  0.002072 -0.003483\n",
    "2016-10-18 -0.000681  0.019616 -0.026168  0.007690\n",
    "2016-10-19 -0.002979  0.007846  0.003583 -0.002255\n",
    "2016-10-20 -0.000512 -0.005652  0.001719 -0.004867\n",
    "2016-10-21 -0.003930  0.003011 -0.012474  0.042096\n",
    "```\n",
    "\n",
    "The `corr` method of a Series calculates the correlation between overlapping, non-missing, aligned-by-index values in two Series. Similarly, the `cov` method computes the covariance:\n",
    "\n",
    "```python\n",
    "returns[\"MSFT\"].corr(returns[\"IBM\"])\n",
    "returns[\"MSFT\"].cov(returns[\"IBM\"])\n",
    "```\n",
    "\n",
    "The correlation between \"MSFT\" and \"IBM\" turns out to be approximately 0.4998, while the covariance is about 8.87e-05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_pickle(\"examples/yahoo_price.pkl\")\n",
    "volume = pd.read_pickle(\"examples/yahoo_volume.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = price.pct_change()\n",
    "returns.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns[\"MSFT\"].corr(returns[\"IBM\"])\n",
    "returns[\"MSFT\"].cov(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, DataFrame's `corr` and `cov` methods provide comprehensive correlation and covariance matrices as DataFrames, respectively:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These methods offer a consolidated view of the relationships between the columns, providing insights into how changes in one stock's price may correlate with changes in another's, or how the volatility of one stock relates to another.\n",
    "\n",
    "Using DataFrames `corrwith` method, you can calculate pair-wise correlations between a DataFrames columns or rows and another Series or DataFrame. \n",
    "\n",
    "When you pass a Series, it returns a Series with correlation values computed for each column:\n",
    "\n",
    "```python\n",
    "returns.corrwith(returns[\"IBM\"])\n",
    "```\n",
    "Output:\n",
    "```\n",
    "AAPL    0.386817\n",
    "GOOG    0.405099\n",
    "IBM     1.000000\n",
    "MSFT    0.499764\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Passing a DataFrame computes correlations of matching column names. For instance, you can calculate correlations of percent changes with volume:\n",
    "\n",
    "```python\n",
    "returns.corrwith(volume)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "AAPL   -0.075565\n",
    "GOOG   -0.007067\n",
    "IBM    -0.204849\n",
    "MSFT   -0.092950\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Passing `axis=\"columns\"` performs calculations row-by-row instead. In all cases, the data points are aligned by label before the correlation is computed. This method provides a convenient way to analyze the relationship between different columns or rows in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corrwith(returns[\"IBM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corrwith(volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Values, Value Counts, and Membership\n",
    "\n",
    "Another set of methods provides insights into the values contained within a one-dimensional Series. Let's illustrate this with an example:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\"])\n",
    "```\n",
    "\n",
    "The first function, `unique`, returns an array of the unique values in a Series:\n",
    "\n",
    "```python\n",
    "uniques = obj.unique()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "array(['c', 'a', 'd', 'b'], dtype=object)\n",
    "```\n",
    "\n",
    "The unique values are not necessarily returned in the order they first appear, nor in sorted order, but they could be sorted after the fact if needed (`uniques.sort()`). \n",
    "\n",
    "Relatedly, `value_counts` computes a Series containing value frequencies:\n",
    "\n",
    "```python\n",
    "obj.value_counts()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "c    3\n",
    "a    3\n",
    "b    2\n",
    "d    1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "The Series is sorted by value in descending order as a convenience. `value_counts` is also available as a top-level pandas method that can be used with NumPy arrays or other Python sequences:\n",
    "\n",
    "```python\n",
    "pd.value_counts(obj.to_numpy(), sort=False)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "c    3\n",
    "a    3\n",
    "d    1\n",
    "b    2\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "These methods offer valuable insights into the distribution of values within a Series, making it easier to understand the data at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = obj.unique()\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(obj.to_numpy(), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isin` method performs a vectorized set membership check, which is useful for filtering a dataset down to a subset of values in a Series or column in a DataFrame:\n",
    "\n",
    "```python\n",
    "obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\"])\n",
    "\n",
    "mask = obj.isin([\"b\", \"c\"])\n",
    "\n",
    "obj[mask]\n",
    "```\n",
    "Output:\n",
    "```\n",
    "0    c\n",
    "5    b\n",
    "6    b\n",
    "7    c\n",
    "8    c\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "The `mask` variable here contains boolean values indicating whether each element of the Series `obj` is present in the specified list `[\"b\", \"c\"]`. Applying this mask to the original Series results in a filtered Series containing only the elements that match the condition.\n",
    "\n",
    "Related to `isin` is the `Index.get_indexer` method, which provides an index array from an array of possibly non-distinct values into another array of distinct values:\n",
    "\n",
    "```python\n",
    "to_match = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"])\n",
    "unique_vals = pd.Series([\"c\", \"b\", \"a\"])\n",
    "\n",
    "indices = pd.Index(unique_vals).get_indexer(to_match)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "array([0, 2, 1, 1, 0, 2])\n",
    "```\n",
    "\n",
    "Here, the `indices` array indicates the index positions of each value in the `to_match` Series within the `unique_vals` Series. This can be useful for mapping values between two Series or arrays.\n",
    "\n",
    "Here's a reference table summarizing the unique, value counts, and set membership methods:\n",
    "\n",
    "Table 5.9: Unique, value counts, and set membership methods\n",
    "\n",
    "| Method       | Description                                                                                      |\n",
    "|--------------|--------------------------------------------------------------------------------------------------|\n",
    "| isin         | Computes a Boolean array indicating whether each Series or DataFrame value is contained in the passed sequence of values |\n",
    "| get_indexer  | Computes integer indices for each value in an array into another array of distinct values; helpful for data alignment and join-type operations |\n",
    "| unique       | Computes an array of unique values in a Series, returned in the order observed                   |\n",
    "| value_counts | Returns a Series containing unique values as its index and frequencies as its values, ordered count in descending order |\n",
    "\n",
    "These methods are commonly used for filtering, data alignment, and obtaining insights into the distribution of values within a Series or DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj\n",
    "mask = obj.isin([\"b\", \"c\"])\n",
    "mask\n",
    "obj[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_match = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"])\n",
    "unique_vals = pd.Series([\"c\", \"b\", \"a\"])\n",
    "indices = pd.Index(unique_vals).get_indexer(to_match)\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain scenarios, you might find it necessary to compute a histogram across multiple related columns within a DataFrame. Here's an illustration:\n",
    "\n",
    "```python\n",
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4],\n",
    "                     \"Qu2\": [2, 3, 1, 2, 3],\n",
    "                     \"Qu3\": [1, 5, 2, 4, 4]})\n",
    "```\n",
    "\n",
    "Let's take a look at the DataFrame:\n",
    "\n",
    "```python\n",
    "data\n",
    "```\n",
    "```\n",
    "   Qu1  Qu2  Qu3\n",
    "0    1    2    1\n",
    "1    3    3    5\n",
    "2    4    1    2\n",
    "3    3    2    4\n",
    "4    4    3    4\n",
    "```\n",
    "\n",
    "We can compute the value counts for a single column, for example, \"Qu1\", like this:\n",
    "\n",
    "```python\n",
    "data[\"Qu1\"].value_counts().sort_index()\n",
    "```\n",
    "```\n",
    "Qu1\n",
    "1    1\n",
    "3    2\n",
    "4    2\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "This gives us the frequency counts of each unique value in the \"Qu1\" column, sorted by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4],\n",
    "                     \"Qu2\": [2, 3, 1, 2, 3],\n",
    "                     \"Qu3\": [1, 5, 2, 4, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Qu1\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the frequency counts for all columns, you can utilize the `apply` method of the DataFrame, passing `pd.value_counts`, and then filling any missing values with 0:\n",
    "\n",
    "```python\n",
    "result = data.apply(pd.value_counts).fillna(0)\n",
    "```\n",
    "\n",
    "This will give you a DataFrame where the row labels represent the distinct values occurring across all columns, and the values represent the respective counts of these values in each column:\n",
    "\n",
    "```python\n",
    "   Qu1  Qu2  Qu3\n",
    "1  1.0  1.0  1.0\n",
    "2  0.0  2.0  1.0\n",
    "3  2.0  2.0  0.0\n",
    "4  2.0  0.0  2.0\n",
    "5  0.0  0.0  1.0\n",
    "```\n",
    "\n",
    "Additionally, there exists a `DataFrame.value_counts` method, but it computes counts by treating each row of the DataFrame as a tuple to determine the occurrences of each distinct row:\n",
    "\n",
    "```python\n",
    "data = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\n",
    "```\n",
    "\n",
    "```python\n",
    "data.value_counts()\n",
    "```\n",
    "\n",
    "This yields a result with an index representing distinct rows as a hierarchical index:\n",
    "\n",
    "```\n",
    "a  b\n",
    "1  0    2\n",
    "2  0    2\n",
    "1  1    1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "The hierarchical index signifies a tuple of values representing each row, which is a topic we will delve into further in Chapter 8: Data Wrangling: Join, Combine, and Reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.apply(pd.value_counts).fillna(0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\n",
    "data\n",
    "data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = PREVIOUS_MAX_ROWS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
